version: '3.9'


x-spark-common: &spark-common
  build:
    context: .
    dockerfile: Dockerfile
  env_file:
    - .env
  environment:
    - MINIO_ROOT_USER=${MINIO_ROOT_USER}
    - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
  command: [ "bash", "-c", "mkdir -p /data && /usr/local/bin/spark-minio-entrypoint.sh" ]

services:
  master:
    <<: *spark-common
    container_name: sp-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_WEBUI_PORT=8081
    volumes:
      - ./:/opt/spark/apps
    networks:
      net-gaming:
        ipv4_address: 192.168.3.100
    ports:
      - "8081:8081"
      - "7077:7077"

  worker1:
    <<: *spark-common
    container_name: sp-worker1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://192.168.3.100:7077
    volumes:
      - ./:/opt/spark/apps
    networks:
      net-gaming:
        ipv4_address: 192.168.3.101
    ports:
      - "9000:9000"
      - "9001:9001"

  spark-history-server:
    <<: *spark-common
    container_name: sp-history-server
    environment:
      - SPARK_MODE=history
      - SPARK_MASTER_URL=spark://192.168.3.100:7077
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=s3a://gaming/spark-events -Dspark.history.ui.port=18080 -Dspark.hadoop.fs.s3a.access.key=${MINIO_ROOT_USER} -Dspark.hadoop.fs.s3a.secret.key=${MINIO_ROOT_PASSWORD} -Dspark.hadoop.fs.s3a.endpoint=http://192.168.3.101:9000 -Dspark.hadoop.fs.s3a.path.style.access=true -Dspark.hadoop.fs.s3a.connection.ssl.enabled=false
    command: [ "bash", "-c", "mkdir -p /data && /usr/local/bin/spark-minio-entrypoint.sh" ]
    networks:
      net-gaming:
        ipv4_address: 192.168.3.102
    ports:
      - '18080:18080'

networks:
  net-gaming:
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.3.0/24
